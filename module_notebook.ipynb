{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "Cyber security Project.ipynb",
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "code",
      "metadata": {
        "id": "vvE8TeyeTqEp",
        "colab": {
          "resources": {
            "http://localhost:8080/nbextensions/google.colab/files.js": {
              "data": "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",
              "ok": true,
              "headers": [
                [
                  "content-type",
                  "application/javascript"
                ]
              ],
              "status": 200,
              "status_text": ""
            }
          },
          "base_uri": "https://localhost:8080/",
          "height": 73
        },
        "outputId": "74b5a3d5-d7e7-45d6-afb9-a5b39d9e8c9b"
      },
      "source": [
        "from google.colab import files\n",
        "file = files.upload()"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/html": [
              "\n",
              "     <input type=\"file\" id=\"files-84b2ee8e-1f92-4c86-bf0e-26340806b449\" name=\"files[]\" multiple disabled\n",
              "        style=\"border:none\" />\n",
              "     <output id=\"result-84b2ee8e-1f92-4c86-bf0e-26340806b449\">\n",
              "      Upload widget is only available when the cell has been executed in the\n",
              "      current browser session. Please rerun this cell to enable.\n",
              "      </output>\n",
              "      <script src=\"/nbextensions/google.colab/files.js\"></script> "
            ],
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ]
          },
          "metadata": {
            "tags": []
          }
        },
        {
          "output_type": "stream",
          "text": [
            "Saving dev-access.csv to dev-access.csv\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "cB-5ZPY5UlUz"
      },
      "source": [
        "import pandas as pd\n",
        "df= pd.read_csv('dev-access.csv',engine='python', quotechar='|', header=None)\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "y-gBtrJAUL_S"
      },
      "source": [
        "def analyze():\n",
        "    dataframe = df.copy()\n",
        "    count_frame = dataframe.groupby([1]).count()\n",
        "    print(count_frame)\n",
        "    total_req = count_frame[0][0] + count_frame[0][1]\n",
        "    num_malicious = count_frame[0][1]\n",
        "    print(\"Total request = \" , total_req)\n",
        "    print(\"Number of Malicious requests = \" , num_malicious)\n",
        "    print(\"Percentage of Malicious request logs in dataset: {:0.2f}%\".format(float(num_malicious) / total_req * 100))"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "sGOhwv63_mpq"
      },
      "source": [
        "import sys\n",
        "import os\n",
        "import json\n",
        "import pandas\n",
        "import numpy\n",
        "import optparse\n",
        "import numpy as np\n",
        "import keras\n",
        "from keras.callbacks import TensorBoard\n",
        "from keras.models import Sequential\n",
        "from keras.layers import LSTM, Dense, Dropout ,SimpleRNN , GRU\n",
        "from keras.layers.embeddings import Embedding\n",
        "from keras.preprocessing import sequence\n",
        "from keras.preprocessing.text import Tokenizer\n",
        "from collections import OrderedDict\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "unRek2Q6V4e-",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "976b7c98-2745-4beb-88cc-f068fd3759c1"
      },
      "source": [
        "analyze()\n",
        "# df.head()"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "       0\n",
            "1       \n",
            "0  13413\n",
            "1  13360\n",
            "Total request =  26773\n",
            "Number of Malicious requests =  13360\n",
            "Percentage of Malicious request logs in dataset: 49.90%\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "LAy52dOa_gqb"
      },
      "source": [
        "def preprocess():\n",
        "    dataframe = df.copy()\n",
        "    dataset = dataframe.sample(frac=1).values\n",
        "\n",
        "    # Preprocess dataset\n",
        "    X = np.asarray(dataset[:,0])\n",
        "    Y = np.asarray(dataset[:,1])\n",
        "\n",
        "    for index, item in enumerate(X):\n",
        "        # Quick hack to space out json elements\n",
        "        reqJson = json.loads(item, object_pairs_hook=OrderedDict)\n",
        "        del reqJson['timestamp']\n",
        "        del reqJson['headers']\n",
        "        del reqJson['source']\n",
        "        del reqJson['route']\n",
        "        del reqJson['responsePayload']\n",
        "        X[index] = json.dumps(reqJson, separators=(',', ':'))\n",
        "\n",
        "    tokenizer = Tokenizer(filters='\\t\\n', char_level=True)\n",
        "    tokenizer.fit_on_texts(X)\n",
        "\n",
        "    # Extract and save word dictionary\n",
        "    word_dict_file = 'build/word-dictionary.json'\n",
        "\n",
        "    if not os.path.exists(os.path.dirname(word_dict_file)):\n",
        "        os.makedirs(os.path.dirname(word_dict_file))\n",
        "\n",
        "    with open(word_dict_file, 'w') as outfile:\n",
        "        json.dump(tokenizer.word_index, outfile, ensure_ascii=False)\n",
        "\n",
        "    num_words = len(tokenizer.word_index)+1\n",
        "    X = tokenizer.texts_to_sequences(X)\n",
        "\n",
        "    max_log_length = 1024\n",
        "    train_size = int(len(dataset) * .75)\n",
        "\n",
        "    X_processed = sequence.pad_sequences(X, maxlen=max_log_length)\n",
        "    X_train, X_test = np.asarray(X_processed[0:train_size]), np.asarray(X_processed[train_size:len(X_processed)])\n",
        "    Y_train, Y_test = np.asarray(Y[0:train_size]), np.asarray(Y[train_size:len(Y)])\n",
        "    # X_train = np.expand_dims(X_train, -1)\n",
        "    # Y_train = np.expand_dims(Y_train, -1)\n",
        "    X_train=np.asarray(X_train).astype(np.float32)\n",
        "    Y_train = np.asarray(Y_train).astype(np.float32)\n",
        "    X_test = np.asarray(X_test).astype(np.float32)\n",
        "    Y_test = np.asarray(Y_test).astype(np.float32)\n",
        "    return X_train, X_test , Y_train, Y_test , num_words , max_log_length\n",
        "\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "AG4BEAvGV6E7"
      },
      "source": [
        "X_train, X_test , Y_train, Y_test,num_words , max_log_length = preprocess()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "9T7W7PH1_XBU",
        "outputId": "68bf925b-8d18-41fa-93d3-4cda67d7ebd3"
      },
      "source": [
        "!pip install scikit-plot"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Collecting scikit-plot\n",
            "  Downloading https://files.pythonhosted.org/packages/7c/47/32520e259340c140a4ad27c1b97050dd3254fdc517b1d59974d47037510e/scikit_plot-0.3.7-py3-none-any.whl\n",
            "Requirement already satisfied: joblib>=0.10 in /usr/local/lib/python3.6/dist-packages (from scikit-plot) (0.17.0)\n",
            "Requirement already satisfied: matplotlib>=1.4.0 in /usr/local/lib/python3.6/dist-packages (from scikit-plot) (3.2.2)\n",
            "Requirement already satisfied: scipy>=0.9 in /usr/local/lib/python3.6/dist-packages (from scikit-plot) (1.4.1)\n",
            "Requirement already satisfied: scikit-learn>=0.18 in /usr/local/lib/python3.6/dist-packages (from scikit-plot) (0.22.2.post1)\n",
            "Requirement already satisfied: pyparsing!=2.0.4,!=2.1.2,!=2.1.6,>=2.0.1 in /usr/local/lib/python3.6/dist-packages (from matplotlib>=1.4.0->scikit-plot) (2.4.7)\n",
            "Requirement already satisfied: numpy>=1.11 in /usr/local/lib/python3.6/dist-packages (from matplotlib>=1.4.0->scikit-plot) (1.18.5)\n",
            "Requirement already satisfied: cycler>=0.10 in /usr/local/lib/python3.6/dist-packages (from matplotlib>=1.4.0->scikit-plot) (0.10.0)\n",
            "Requirement already satisfied: python-dateutil>=2.1 in /usr/local/lib/python3.6/dist-packages (from matplotlib>=1.4.0->scikit-plot) (2.8.1)\n",
            "Requirement already satisfied: kiwisolver>=1.0.1 in /usr/local/lib/python3.6/dist-packages (from matplotlib>=1.4.0->scikit-plot) (1.3.1)\n",
            "Requirement already satisfied: six in /usr/local/lib/python3.6/dist-packages (from cycler>=0.10->matplotlib>=1.4.0->scikit-plot) (1.15.0)\n",
            "Installing collected packages: scikit-plot\n",
            "Successfully installed scikit-plot-0.3.7\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ANZkx1LCnWPY"
      },
      "source": [
        "from sklearn.metrics import confusion_matrix, recall_score ,precision_score , fbeta_score ,cohen_kappa_score  ,log_loss , roc_auc_score\n",
        "from scikitplot.metrics import plot_roc\n",
        "import matplotlib as plt\n",
        "\n",
        "def performance_measures(y_true , y_pred_pos):\n",
        "  #confusion matrix\n",
        "  print(\"Confusion matrix\")\n",
        "  y_pred_class = y_pred_pos > 0.5\n",
        "  cm = confusion_matrix(y_true, y_pred_class)\n",
        "  print(cm)\n",
        "  tn, fp, fn, tp = cm.ravel()\n",
        "  \n",
        "  #recall score\n",
        "  print(\"Recall score = \" , recall_score(y_true, y_pred_class))\n",
        "\n",
        "  #precision score\n",
        "  print(\"Precision score = \" , precision_score(y_true, y_pred_class))\n",
        "\n",
        "  #beta scores\n",
        "  print(\"F1 score =\",fbeta_score(y_true, y_pred_class, 1))\n",
        "  print(\"F2 score =\", fbeta_score(y_true, y_pred_class, 2))\n",
        "\n",
        "  #cohen-capa\n",
        "  print(\"Cohen capa score = \" , cohen_kappa_score(y_true, y_pred_class))\n",
        "\n",
        "  # #roc-curve\n",
        "  # fig, ax = plt.subplots()\n",
        "  # plot_roc(y_true, y_pred_pos, ax=ax)\n",
        "\n",
        "  #log-loss\n",
        "  print(\"Log - loss = \", log_loss(y_true, y_pred_pos))\n",
        "\n",
        "  #roc_auc\n",
        "  print(\"Roc_auc score=\", roc_auc_score(y_true, y_pred_pos))\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "M1b4wHL9XkT-"
      },
      "source": [
        "from keras.layers import Bidirectional\n",
        "def train_lstm(is_bidirectional=False):\n",
        "    tb_callback = TensorBoard(log_dir='./logs', embeddings_freq=1)\n",
        "\n",
        "    model = Sequential()\n",
        "    model.add(Embedding(num_words, 32, input_length=max_log_length))\n",
        "    model.add(Dropout(0.5))\n",
        "    if is_bidirectional==True:\n",
        "      model.add(Bidirectional(LSTM(64, recurrent_dropout=0.5)))\n",
        "    else:\n",
        "      model.add(LSTM(64, recurrent_dropout=0.5))\n",
        "    model.add(Dropout(0.5))\n",
        "    model.add(Dense(1, activation='sigmoid'))\n",
        "    model.compile(loss='binary_crossentropy', optimizer='adam', metrics=['accuracy'])\n",
        "    print(model.summary())\n",
        "    model.fit(X_train, Y_train, validation_split=0.25, epochs=3, batch_size=128)\n",
        "\n",
        "    # return model\n",
        "\n",
        "    # Evaluate model\n",
        "    score, acc = model.evaluate(X_test, Y_test, verbose=1, batch_size=128)\n",
        "\n",
        "    print(\"Model Accuracy: {:0.2f}%\".format(acc * 100))\n",
        "    \n",
        "    pred = model.predict(X_test)\n",
        "    num_false_positives = 0\n",
        "    num_dealt_with=0\n",
        "    for i in range(len(X_test)):\n",
        "      if Y_test[i]==0 and pred[i]>=0.50:\n",
        "        num_false_positives+=1\n",
        "        if pred[i]<=0.60:\n",
        "          num_dealt_with+=1\n",
        "\n",
        "    print(\"Number of false positives = \" , num_false_positives)\n",
        "    print(\"Number of false positives that are solved with the hueristic method\" , num_dealt_with)\n",
        "    if num_false_positives!=0:\n",
        "      print(\"Percentage dealth with = \" , (num_dealt_with*1.0/num_false_positives)*100)\n",
        "\n",
        "    performance_measures(Y_test ,pred)\n",
        "    return model , Y_test , pred\n",
        "\n",
        "\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "8SRZGe5PZhe_",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "328c8f64-7719-45a9-a14c-6001145ed22b"
      },
      "source": [
        "#normal\n",
        "lstm_model , Y_test , pred = train_lstm(False)\n"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "WARNING:tensorflow:Layer lstm will not use cuDNN kernel since it doesn't meet the cuDNN kernel criteria. It will use generic GPU kernel as fallback when running on GPU\n",
            "Model: \"sequential_8\"\n",
            "_________________________________________________________________\n",
            "Layer (type)                 Output Shape              Param #   \n",
            "=================================================================\n",
            "embedding_8 (Embedding)      (None, 1024, 32)          2016      \n",
            "_________________________________________________________________\n",
            "dropout_16 (Dropout)         (None, 1024, 32)          0         \n",
            "_________________________________________________________________\n",
            "lstm (LSTM)                  (None, 64)                24832     \n",
            "_________________________________________________________________\n",
            "dropout_17 (Dropout)         (None, 64)                0         \n",
            "_________________________________________________________________\n",
            "dense_8 (Dense)              (None, 1)                 65        \n",
            "=================================================================\n",
            "Total params: 26,913\n",
            "Trainable params: 26,913\n",
            "Non-trainable params: 0\n",
            "_________________________________________________________________\n",
            "None\n",
            "Epoch 1/3\n",
            "118/118 [==============================] - 438s 4s/step - loss: 0.6764 - accuracy: 0.6048 - val_loss: 0.6130 - val_accuracy: 0.6233\n",
            "Epoch 2/3\n",
            "118/118 [==============================] - 442s 4s/step - loss: 0.3516 - accuracy: 0.8464 - val_loss: 0.1027 - val_accuracy: 0.9771\n",
            "Epoch 3/3\n",
            "118/118 [==============================] - 441s 4s/step - loss: 0.1306 - accuracy: 0.9644 - val_loss: 0.1239 - val_accuracy: 0.9693\n",
            "53/53 [==============================] - 17s 327ms/step - loss: 0.1472 - accuracy: 0.9649\n",
            "Model Accuracy: 96.49%\n",
            "Number of false positives =  88\n",
            "Number of false positives that are solved with the hueristic method 25\n",
            "Percentage dealth with =  28.40909090909091\n",
            "Confusion matrix\n",
            "[[3277   88]\n",
            " [ 147 3182]]\n",
            "Recall score =  0.9558425953739862\n",
            "Precision score =  0.9730886850152906\n",
            "F1 score = 0.9643885437187453\n",
            "F2 score = 0.9592427348366093\n",
            "Cohen capa score =  0.9297791817765216\n",
            "Log - loss =  0.1472356853882685\n",
            "Roc_auc score= 0.9819939323795526\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "wj90C5cmYrCK",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "0ef865fe-e091-41de-cd3b-fd8d9dd753b9"
      },
      "source": [
        "# Bidirectional\n",
        "lstm_model,Y_test , pred = train_lstm(True)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "WARNING:tensorflow:Layer lstm_1 will not use cuDNN kernel since it doesn't meet the cuDNN kernel criteria. It will use generic GPU kernel as fallback when running on GPU\n",
            "WARNING:tensorflow:Layer lstm_1 will not use cuDNN kernel since it doesn't meet the cuDNN kernel criteria. It will use generic GPU kernel as fallback when running on GPU\n",
            "WARNING:tensorflow:Layer lstm_1 will not use cuDNN kernel since it doesn't meet the cuDNN kernel criteria. It will use generic GPU kernel as fallback when running on GPU\n",
            "Model: \"sequential_9\"\n",
            "_________________________________________________________________\n",
            "Layer (type)                 Output Shape              Param #   \n",
            "=================================================================\n",
            "embedding_9 (Embedding)      (None, 1024, 32)          2016      \n",
            "_________________________________________________________________\n",
            "dropout_18 (Dropout)         (None, 1024, 32)          0         \n",
            "_________________________________________________________________\n",
            "bidirectional (Bidirectional (None, 128)               49664     \n",
            "_________________________________________________________________\n",
            "dropout_19 (Dropout)         (None, 128)               0         \n",
            "_________________________________________________________________\n",
            "dense_9 (Dense)              (None, 1)                 129       \n",
            "=================================================================\n",
            "Total params: 51,809\n",
            "Trainable params: 51,809\n",
            "Non-trainable params: 0\n",
            "_________________________________________________________________\n",
            "None\n",
            "Epoch 1/3\n",
            "118/118 [==============================] - 880s 7s/step - loss: 0.5169 - accuracy: 0.7277 - val_loss: 0.2180 - val_accuracy: 0.9131\n",
            "Epoch 2/3\n",
            "118/118 [==============================] - 879s 7s/step - loss: 0.1692 - accuracy: 0.9441 - val_loss: 0.1002 - val_accuracy: 0.9707\n",
            "Epoch 3/3\n",
            "118/118 [==============================] - 883s 7s/step - loss: 0.1174 - accuracy: 0.9642 - val_loss: 0.0911 - val_accuracy: 0.9753\n",
            "53/53 [==============================] - 34s 649ms/step - loss: 0.0973 - accuracy: 0.9740\n",
            "Model Accuracy: 97.40%\n",
            "Number of false positives =  45\n",
            "Number of false positives that are solved with the hueristic method 3\n",
            "Percentage dealth with =  6.666666666666667\n",
            "Confusion matrix\n",
            "[[3320   45]\n",
            " [ 129 3200]]\n",
            "Recall score =  0.9612496245118655\n",
            "Precision score =  0.9861325115562404\n",
            "F1 score = 0.9735320961362945\n",
            "F2 score = 0.9661252339834551\n",
            "Cohen capa score =  0.9480046244062692\n",
            "Log - loss =  0.09734273410479646\n",
            "Roc_auc score= 0.9939931271723077\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "4JlscXQjZlF0"
      },
      "source": [
        "ydd =[]\n",
        "ddd= []\n",
        "\n",
        "def train_vanilla_RNN(is_bidirectional=False):\n",
        "    tb_callback = TensorBoard(log_dir='./logs', embeddings_freq=1)\n",
        "\n",
        "    model = Sequential()\n",
        "    model.add(Embedding(num_words, 32, input_length=max_log_length))\n",
        "    model.add(Dropout(0.5))\n",
        "    if is_bidirectional==True:\n",
        "      model.add(Bidirectional(SimpleRNN(10, recurrent_dropout=0.5)))\n",
        "    else:\n",
        "      model.add(SimpleRNN(10, recurrent_dropout=0.5))\n",
        "    model.add(Dropout(0.5))\n",
        "    model.add(Dense(1, activation='sigmoid'))\n",
        "    opt = keras.optimizers.Adam(learning_rate=0.0001)\n",
        "    model.compile(loss='binary_crossentropy', optimizer=opt, metrics=['accuracy'])\n",
        "    print(model.summary())\n",
        "    model.fit(X_train, Y_train, validation_split=0.25, epochs=3, batch_size=128)\n",
        "\n",
        "    # return model\n",
        "\n",
        "    # Evaluate model\n",
        "    score, acc = model.evaluate(X_test, Y_test, verbose=1, batch_size=128)\n",
        "\n",
        "    print(\"Model Accuracy: {:0.2f}%\".format(acc * 100))\n",
        "    # # Save model\n",
        "    # model.save_weights('securitai-lstm-weights.h5')\n",
        "    # model.save('securitai-lstm-model.h5')\n",
        "    # with open('securitai-lstm-model.json', 'w') as outfile:\n",
        "    #     outfile.write(model.to_json())\n",
        "    # return model\n",
        "    pred = model.predict(X_test)\n",
        "    num_false_positives = 0\n",
        "    num_dealt_with=0\n",
        "    for i in range(len(X_test)):\n",
        "      if Y_test[i]==0 and pred[i]>=0.50:\n",
        "        num_false_positives+=1\n",
        "        if pred[i]<=0.60:\n",
        "          num_dealt_with+=1\n",
        "    \n",
        "    # performance_measures(Y_test ,pred)\n",
        "    # print(\"Number of false positives = \" , num_false_positives)\n",
        "    # print(\"Number of false positives that are solved with the hueristic method\" , num_dealt_with)\n",
        "    # print(\"Percentage dealth with = \" , (num_dealt_with*1.0/num_false_positives)*100)\n",
        "\n",
        "    performance_measures(Y_test ,pred)\n",
        "    return model\n",
        "\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "4Un1qn-e4caf",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "5809ebb7-5eb4-43fd-9659-3d5811dd32fa"
      },
      "source": [
        "# Normal\n",
        "vanilla_RNN_model, Y_test , pred = train_vanilla_RNN(False)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Model: \"sequential_4\"\n",
            "_________________________________________________________________\n",
            "Layer (type)                 Output Shape              Param #   \n",
            "=================================================================\n",
            "embedding_4 (Embedding)      (None, 1024, 32)          2016      \n",
            "_________________________________________________________________\n",
            "dropout_8 (Dropout)          (None, 1024, 32)          0         \n",
            "_________________________________________________________________\n",
            "simple_rnn_4 (SimpleRNN)     (None, 10)                430       \n",
            "_________________________________________________________________\n",
            "dropout_9 (Dropout)          (None, 10)                0         \n",
            "_________________________________________________________________\n",
            "dense_4 (Dense)              (None, 1)                 11        \n",
            "=================================================================\n",
            "Total params: 2,457\n",
            "Trainable params: 2,457\n",
            "Non-trainable params: 0\n",
            "_________________________________________________________________\n",
            "None\n",
            "118/118 [==============================] - 122s 1s/step - loss: 0.8208 - accuracy: 0.5034 - val_loss: 0.6987 - val_accuracy: 0.4739\n",
            "53/53 [==============================] - 4s 71ms/step - loss: 0.7000 - accuracy: 0.4676\n",
            "Model Accuracy: 46.76%\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "RTbspPPlY2Ws",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "3eef76a3-a040-406c-d0d7-dac49e1fc0d4"
      },
      "source": [
        "# Bidrectional\n",
        "vanilla_RNN_model = train_vanilla_RNN(True)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Model: \"sequential_7\"\n",
            "_________________________________________________________________\n",
            "Layer (type)                 Output Shape              Param #   \n",
            "=================================================================\n",
            "embedding_7 (Embedding)      (None, 1024, 32)          2016      \n",
            "_________________________________________________________________\n",
            "dropout_14 (Dropout)         (None, 1024, 32)          0         \n",
            "_________________________________________________________________\n",
            "bidirectional_2 (Bidirection (None, 20)                860       \n",
            "_________________________________________________________________\n",
            "dropout_15 (Dropout)         (None, 20)                0         \n",
            "_________________________________________________________________\n",
            "dense_7 (Dense)              (None, 1)                 21        \n",
            "=================================================================\n",
            "Total params: 2,897\n",
            "Trainable params: 2,897\n",
            "Non-trainable params: 0\n",
            "_________________________________________________________________\n",
            "None\n",
            "Epoch 1/3\n",
            "118/118 [==============================] - 234s 2s/step - loss: 0.7774 - accuracy: 0.4929 - val_loss: 0.6954 - val_accuracy: 0.5080\n",
            "Epoch 2/3\n",
            "118/118 [==============================] - 232s 2s/step - loss: 0.7717 - accuracy: 0.4938 - val_loss: 0.6950 - val_accuracy: 0.5100\n",
            "Epoch 3/3\n",
            "118/118 [==============================] - 235s 2s/step - loss: 0.7679 - accuracy: 0.4992 - val_loss: 0.6948 - val_accuracy: 0.5084\n",
            "53/53 [==============================] - 7s 138ms/step - loss: 0.6968 - accuracy: 0.4979\n",
            "Model Accuracy: 49.79%\n",
            "Confusion matrix\n",
            "[[  39 3317]\n",
            " [  44 3294]]\n",
            "Recall score =  0.9868184541641701\n",
            "Precision score =  0.4982604749659658\n",
            "F1 score = 0.6621771032264548\n",
            "F2 score = 0.8250262986525071\n",
            "Cohen capa score =  -0.0015564756625949805\n",
            "Log - loss =  0.6967980111663934\n",
            "Roc_auc score= 0.47576133282296323\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "iCb7ORmmK7lm",
        "outputId": "1742237f-a883-42fb-82de-879a8b1b3864"
      },
      "source": [
        "performance_measures(Y_test,pred)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Confusion matrix\n",
            "[[ 550 2806]\n",
            " [ 758 2580]]\n",
            "Recall score =  0.7729179149191132\n",
            "Precision score =  0.4790196806535462\n",
            "F1 score = 0.591471801925722\n",
            "F2 score = 0.6884406019852706\n",
            "Cohen capa score =  -0.06309269603841461\n",
            "Log - loss =  0.7000138760904144\n",
            "Roc_auc score= 0.5449097723258951\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "KjFMK9efJaTX",
        "outputId": "859e58c0-3cc9-49f1-d9a3-fad92b883a4e"
      },
      "source": [
        "print(performance_measures(Y_test,pred))"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Confusion matrix\n",
            "[[ 550 2806]\n",
            " [ 758 2580]]\n",
            "Recall score =  0.7729179149191132\n",
            "Precision score =  0.4790196806535462\n",
            "F1 score = 0.591471801925722\n",
            "F2 score = 0.6884406019852706\n",
            "Cohen capa score =  -0.06309269603841461\n",
            "Log - loss =  0.7000138760904144\n",
            "Roc_auc score= 0.5449097723258951\n",
            "None\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "OU7t4nfyE4EV"
      },
      "source": [
        ""
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Wb4hQikb4hMP"
      },
      "source": [
        "def train_GRU(is_bidirectional=False):\n",
        "    tb_callback = TensorBoard(log_dir='./logs', embeddings_freq=1)\n",
        "\n",
        "    tb_callback = TensorBoard(log_dir='./logs', embeddings_freq=1)\n",
        "\n",
        "    model = Sequential()\n",
        "    model.add(Embedding(num_words, 32, input_length=max_log_length))\n",
        "    model.add(Dropout(0.5))\n",
        "    if is_bidirectional==True:\n",
        "      model.add(Bidirectional(GRU(64, recurrent_dropout=0.5)))\n",
        "    else:\n",
        "      model.add(GRU(64, recurrent_dropout=0.5))\n",
        "    model.add(Dropout(0.5))\n",
        "    model.add(Dense(1, activation='sigmoid'))\n",
        "    model.compile(loss='binary_crossentropy', optimizer='adam', metrics=['accuracy'])\n",
        "    print(model.summary())\n",
        "    model.fit(X_train, Y_train, validation_split=0.25, epochs=1, batch_size=128)\n",
        "\n",
        "    # return model\n",
        "\n",
        "    # Evaluate model\n",
        "    score, acc = model.evaluate(X_test, Y_test, verbose=1, batch_size=128)\n",
        "\n",
        "    print(\"Model Accuracy: {:0.2f}%\".format(acc * 100))\n",
        "    # # Save model\n",
        "    # model.save_weights('securitai-lstm-weights.h5')\n",
        "    # model.save('securitai-lstm-model.h5')\n",
        "    # with open('securitai-lstm-model.json', 'w') as outfile:\n",
        "    #     outfile.write(model.to_json())\n",
        "    # return model\n",
        "    pred = model.predict(X_test)\n",
        "    # return model  , pred\n",
        "    num_false_positives = 0\n",
        "    num_dealt_with=0\n",
        "    for i in range(len(X_test)):\n",
        "      if Y_test[i]==0 and pred[i]>=0.50:\n",
        "        num_false_positives+=1\n",
        "        if pred[i]<=0.60:\n",
        "          num_dealt_with+=1\n",
        "    \n",
        "    performance_measures(Y_test, pred)\n",
        "    \n",
        "\n",
        "    print(\"Number of false positives = \" , num_false_positives)\n",
        "    print(\"Number of false positives that are solved with the hueristic method\" , num_dealt_with)\n",
        "    print(\"Percentage dealth with = \" , (num_dealt_with*1.0/num_false_positives)*100)\n",
        "\n",
        "    return model , pred\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "1j8sYWPE5lwn",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "e8ddf02f-b398-4735-b233-c5bd03cb1c55"
      },
      "source": [
        "#normal\n",
        "gru_model , pred = train_GRU(False)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "WARNING:tensorflow:Layer gru_2 will not use cuDNN kernel since it doesn't meet the cuDNN kernel criteria. It will use generic GPU kernel as fallback when running on GPU\n",
            "Model: \"sequential_7\"\n",
            "_________________________________________________________________\n",
            "Layer (type)                 Output Shape              Param #   \n",
            "=================================================================\n",
            "embedding_7 (Embedding)      (None, 1024, 32)          2016      \n",
            "_________________________________________________________________\n",
            "dropout_14 (Dropout)         (None, 1024, 32)          0         \n",
            "_________________________________________________________________\n",
            "gru_2 (GRU)                  (None, 64)                18816     \n",
            "_________________________________________________________________\n",
            "dropout_15 (Dropout)         (None, 64)                0         \n",
            "_________________________________________________________________\n",
            "dense_7 (Dense)              (None, 1)                 65        \n",
            "=================================================================\n",
            "Total params: 20,897\n",
            "Trainable params: 20,897\n",
            "Non-trainable params: 0\n",
            "_________________________________________________________________\n",
            "None\n",
            "118/118 [==============================] - 404s 3s/step - loss: 0.6498 - accuracy: 0.5961 - val_loss: 0.6016 - val_accuracy: 0.6257\n",
            "53/53 [==============================] - 16s 302ms/step - loss: 0.5983 - accuracy: 0.6243\n",
            "Model Accuracy: 62.43%\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "HKuobQP0Kdtw",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 180
        },
        "outputId": "ea664416-b352-4f12-9c91-fc5285fd1882"
      },
      "source": [
        "#bidrectional\n",
        "gru_model = train_GRU(True)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "error",
          "ename": "NameError",
          "evalue": "ignored",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-1-c666576c0ec9>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[0;31m#bidrectional\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 2\u001b[0;31m \u001b[0mgru_model\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtrain_GRU\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;32mTrue\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
            "\u001b[0;31mNameError\u001b[0m: name 'train_GRU' is not defined"
          ]
        }
      ]
    }
  ]
}